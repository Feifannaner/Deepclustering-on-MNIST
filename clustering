import torch
import numpy as np
import torch.utils.data as data
import torchvision.transforms as transforms
from sklearn.decomposition import PCA
from sklearn.cluster import KMeans
from sklearn.neighbors import NearestNeighbors
from sklearn.datasets.samples_generator import make_blobs

def preprocess_features(data, n_pca = 256):
    data = data.astype('float32')
    # Apply PCA-whitening
    pca = PCA(2, whiten = True)
    pca.fit(data)
    data = pca.transform(data)
    return data

def run_kmeans(x, num_cluster=10):
    kmeans = KMeans(n_clusters=num_cluster, random_state=1).fit(x)
    pseudolabels = kmeans.predict(x)
    return pseudolabels

class ReassignedDataset(data.Dataset):
    """A dataset where the new images labels are given in argument.
    Args:
        image_indexes (list): list of data indexes
        pseudolabels (list): list of labels for each data
        dataset (list): list of tuples with paths to images
        transform (callable, optional): a function/transform that takes in
                                        an PIL image and returns a
                                        transformed version
    """

    def __init__(self, image_indexes, pseudolabels, dataset, transform=None):
        self.imgs = self.make_dataset(image_indexes, pseudolabels, dataset)
        self.transform = transform

    def make_dataset(self, image_indexes, pseudolabels, dataset):
        label_to_idx = {label: idx for idx, label in enumerate(set(pseudolabels))}
        images = []
        for j, idx in enumerate(image_indexes):
            path = dataset[idx][0]
            pseudolabel = label_to_idx[pseudolabels[j]]
            images.append((path, pseudolabel))
        return images

    def __getitem__(self, index):
        """
        Args:
            index (int): index of data
        Returns:
            tuple: (image, pseudolabel) where pseudolabel is the cluster of index datapoint
        """
        path, pseudolabel = self.imgs[index]
        # img = pil_loader(path)
        img = path
        if self.transform is not None:
            img = self.transform(path)
        # print(img)
        return img, pseudolabel

    def __len__(self):
        return len(self.imgs)

def cluster_assign(images_lists, dataset):
    pseudolabels = []
    image_indexes = []
    for cluster, images in enumerate(images_lists):
        image_indexes.extend(images)
        pseudolabels.extend([cluster] * len(images))
    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],
                                    std=[0.229, 0.224, 0.225])
    t = transforms.Compose([transforms.RandomHorizontalFlip(),
                            transforms.ToTensor(),
                            normalize])
    return ReassignedDataset(image_indexes, pseudolabels, dataset, t)

class Kmeans:
    def __init__(self, k):
        self.k = k
    def cluster(self, data):
        # PCA-reducing, whitening
        xb = preprocess_features(data)
        # cluster the data
        I = run_kmeans(xb, self.k)
        self.images_lists = [[] for i in range(self.k)]
        for i in range(len(I)):
            self.images_lists[I[i]].append(i)
        return self.images_lists        #images_lists -> [[2, 3, 4], [5, 6], [1], [0]]

def arrange_clustering(images_lists):
    pseudolabels = []
    image_indexes = []
    for cluster, images in enumerate(images_lists):
        image_indexes.extend(images)
        pseudolabels.extend([cluster] * len(images))
    indexes = np.argsort(image_indexes)
    return np.asarray(pseudolabels)[indexes]
    # pseudolabels  -> [0, 0, 0, 1, 1, 2, 3]
    # image_indexes -> [2, 3, 4, 5, 6, 1, 0]
